<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<!-- saved from url=(0040)http://people.eecs.berkeley.edu/~barron/ -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=windows-1252">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    a {
    color: #1772d0;
    text-decoration:none;
    }
    a:focus, a:hover {
    color: #f09228;
    text-decoration:none;
    }
    body,td,th,tr,p,a {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px
    }
    strong {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    }
    heading {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 22px;
    }
    papertitle {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    font-weight: 700
    }
    name {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 32px;
    }
    .one
    {
    width: 160px;
    height: 160px;
    position: relative;
    }
    .two
    {
    width: 160px;
    height: 160px;
    position: absolute;
    transition: opacity .2s ease-in-out;
    -moz-transition: opacity .2s ease-in-out;
    -webkit-transition: opacity .2s ease-in-out;
    }
    .fade {
     transition: opacity .2s ease-in-out;
     -moz-transition: opacity .2s ease-in-out;
     -webkit-transition: opacity .2s ease-in-out;
    }
    span.highlight {
        background-color: #ffffd0;
    }
  </style>
  
  <title>Aseem</title>
  
  <link href="./website_files/css" rel="stylesheet" type="text/css">
  </head>
  <body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tbody><tr>
    <td>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tbody><tr>
        <td width="67%" valign="middle">
        <p align="center">
          <name>Aseem Saxena</name>
        </p>
        <p>I am a computer Vision Engineer at <a href="https://duceretech.com/">Ducere Technologies</a>, where I work in the Interaction Design Team. At Ducere I am working on developing a low power, low cost LiDAR system. I am also working on online handwriting recognition.
        </p>
        <p>
          I did my Bachelors at <a href="http://www.bits-pilani.ac.in/">BITS Pilani</a>, my education was funded by  the <a href="http://kvpy.iisc.ernet.in/main/index.htm">KVPY Fellowship</a>. I've spent time at <a href="http://robotics.iiit.ac.in/">Robotics Research Lab, IIIT Hyderabad</a>, where I was advised by Prof Madhava Krishna. 
        </p>
        <p align="center">
<a href="mailto:aseem.bits@gmail.com">Email</a> &nbsp;/&nbsp;
<a href="website_files/CV_Fall17.pdf">CV</a> &nbsp;/&nbsp;
<a href="https://github.com/aseembits93">Github</a> &nbsp;/&nbsp;
<a href="https://scholar.google.co.in/citations?user=LJQoO7AAAAAJ&hl=en">Google Scholar</a> &nbsp;/&nbsp;  
<a href="http://www.facebook.com/aseem.saxena.5">Facebook</a> &nbsp;/&nbsp; 
<a href="http://www.linkedin.com/in/aseembits93/"> LinkedIn </a>
        </p>
        </td>
        
      </tr>
      </tbody></table>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tbody><tr>
        <td width="100%" valign="middle">
          <heading>Research Interests</heading>
          <p>
          I am interested in Artificial Intelligence, Computer Vision, Machine Learning, Statistics and Optimization. I have also worked on Protein Structure Prediction and Cancer Genomics. 
          </p>
        </td>
      </tr>
      </tbody></table>
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tbody><tr>
        <td>
        <heading>Publications</heading>
        </td>
      </tr>
      </tbody></table>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        
        
        <tbody><tr >
          <td width="25%">

            <div class="one">
                
                <img src="website_files/pipeline_160.png">
            </div>                
            
              </td>
              <td valign="top" width="75%">
              <p><a href="https://aseembits93.github.io/website_files/Servonets_ICRA_16_V3.pdf">
        <papertitle>Exploring Convolutional Networks for End-to-End Visual Servoing</papertitle></a><br>
        <strong>Aseem Saxena</strong>, <strong>Harit Pandya</strong>, Gourav Kumar, K. Madhava Krishna<br>
                <em>IEEE ICRA</em>, 2017 (Accepted)<br>
                <a href="https://www.youtube.com/watch?v=Ve6-3sNBfEM">video</a>
                
                
              </p><p></p>
              <p> We present an end-to-end learning based approach for visual servoing in diverse scenes where the knowledge of camera parameters and scene geometry is not available apriori. This is achieved by training a convolutional neural network over color images with synchronised camera poses.</p>
              
              <p></p>
              <p></p>
              </td>
            </tr>

        
        
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tbody><tr>
        <td>
        <heading>Projects</heading>
        </td>
      </tr>
      </tbody></table>
      <table width="100%" align="center" border="0" cellpadding="20">
      <tbody><tr>
        <td width="25%"><img src="website_files/gffrwn_160.png" alt="prl" width="160" height="160"></td>
        <td width="75%" valign="top">
        <p>
          <a href="http://robotics.iiit.ac.in/uploads/Main/Publications/Siva_etal_ICVGIP_14.pdf">
          <papertitle>Guess from Far, Recognize when Near: Searching the
Floor for Small Objects</papertitle>
          </a>
          <br>
          <strong>M Siva Karthik</strong>, Sudhanshu Mittal, K. Madhava Krishna, ICVGIP 2014
        <br>
<a href="https://www.youtube.com/watch?v=CbrLFqt_a9I">video</a>
                
                
              </p><p></p>

<p>          Object recognition is achieved using 3-D Point Cloud data from Kinect sensors and constructing a Bag of Words Model on it. It is trained using a Support Vector Machine Classifier. Object Detection is achieved using segmentation of 2-D images by Markov Random Fields. The implementation is done on a Turtlebot with a Kinect Sensor mounted on top of it.
        </p>
        <p></p>
        </td>
      </tr>
      <tr onmouseout="cvpr2012_stop()" onmouseover="cvpr2012_start()">
        <td width="25%">
            <div class="one">
                <div class="two" id="cvpr2012_image" style="opacity: 0;">
                  <img src="website_files/table_out160.png" style="border-style: none"></div>
                <img src="website_files/table_in160.png" style="border-style: none">
            </div>                
            <script type="text/javascript">
            function cvpr2012_start() {
              document.getElementById('cvpr2012_image').style.opacity = "1";
            }
            function cvpr2012_stop() {
              document.getElementById('cvpr2012_image').style.opacity = "0";
            }
            cvpr2012_stop()
            </script>
        </td>
        <td width="75%" valign="top">
        <p>
          <a href="website_files/tabledeepreport.pdf">
          <papertitle>Deep Learning for Table Interest Point Detection</papertitle>
          </a>
          <br>
          <strong>Aseem Saxena</strong>
        </p>
		<p>I attempt to find interest points or corner points of tables in a scene using cues from
semantic segmentation and vanishing lines. Availabilty of semantic information such as
interest points can help mobile robots navigate in a better way.</p>
        </td>
      </tr>
<tr onmouseout="cvpr12012_stop()" onmouseover="cvpr12012_start()">
        <td width="25%">
            <div class="one">
                <div class="two" id="cvpr12012_image" style="opacity: 0;">
                  <img src="website_files/2_out_160.png" style="border-style: none"></div>
                <img src="website_files/2_in_160.png" style="border-style: none">
            </div>                
            <script type="text/javascript">
            function cvpr12012_start() {
              document.getElementById('cvpr12012_image').style.opacity = "1";
            }
            function cvpr12012_stop() {
              document.getElementById('cvpr12012_image').style.opacity = "0";
            }
            cvpr12012_stop()
            </script>
        </td>
        <td width="75%" valign="top">
        <p>
          <a href="website_files/grabcutreport.pdf">
          <papertitle>Automating GrabCut for Multilabel Image Segmentation</papertitle>
          </a>
          <br>
          <strong>Aseem Saxena</strong>
        </p>
		<p>Performing Image Segmentation for 3 labels without user guidance by learning a GMM
for each label and performing alpha expansion algorithm using MRF2.2 Library.</p>
        </td>
      </tr>
  
        
        
      </tbody></table>
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tbody><tr>
        <td>
        <br>
        <p align="right"><font size="2">
          Shamelessly copied from 
          <a href="https://people.eecs.berkeley.edu/~barron/">this</a>
          </font>
        </p>
        </td>
      </tr>
      </tbody></table>
      
  

</body></html>
